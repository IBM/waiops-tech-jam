"use strict";(self.webpackChunkswat_hub=self.webpackChunkswat_hub||[]).push([[1570],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(n),m=i,u=p["".concat(l,".").concat(m)]||p[m]||h[m]||o;return n?a.createElement(u,r(r({ref:t},d),{},{components:n})):a.createElement(u,r({ref:t},d))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var c=2;c<o;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},2282:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var a=n(87462),i=(n(67294),n(3905));const o={title:"4. Mediating CSV Metric Data",description:"This lab will illustrate how to analyze CSV file structure, how to create a Metric Manager topic model, how to deploy the model to a topic, and how to start ingestion of CSV data for machine learning",sidebar_position:4},r=void 0,s={unversionedId:"metric-management/mm-mediating-csv/index",id:"metric-management/mm-mediating-csv/index",title:"4. Mediating CSV Metric Data",description:"This lab will illustrate how to analyze CSV file structure, how to create a Metric Manager topic model, how to deploy the model to a topic, and how to start ingestion of CSV data for machine learning",source:"@site/labs/metric-management/4-mm-mediating-csv/index.mdx",sourceDirName:"metric-management/4-mm-mediating-csv",slug:"/metric-management/mm-mediating-csv/",permalink:"/waiops-tech-jam/labs/metric-management/mm-mediating-csv/",draft:!1,editUrl:"https://github.com/IBM/waiops-tech-jam/labs/metric-management/4-mm-mediating-csv/index.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"4. Mediating CSV Metric Data",description:"This lab will illustrate how to analyze CSV file structure, how to create a Metric Manager topic model, how to deploy the model to a topic, and how to start ingestion of CSV data for machine learning",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"3. Installing Metric Manager",permalink:"/waiops-tech-jam/labs/metric-management/mm-install/"},next:{title:"5. Reviewing Ingestion Results",permalink:"/waiops-tech-jam/labs/metric-management/mm-analyzing-results/"}},l={},c=[{value:"4-1: <strong>Introduction</strong>",id:"4-1-introduction",level:2},{value:"4-2: <strong>Creating a topic</strong>",id:"4-2-creating-a-topic",level:2},{value:"4-3: <strong>Topic configuration</strong>",id:"4-3-topic-configuration",level:2},{value:"Topic configuration considerations",id:"topic-configuration-considerations",level:3},{value:"Configuring topic options",id:"configuring-topic-options",level:3},{value:"4-4: <strong>Creating a model to ingest CSV</strong>",id:"4-4-creating-a-model-to-ingest-csv",level:2},{value:"Create a data source",id:"create-a-data-source",level:3},{value:"Configure the filesystem details.",id:"configure-the-filesystem-details",level:3},{value:"Defining the model from the data",id:"defining-the-model-from-the-data",level:3},{value:"4-5: Deploying the model",id:"4-5-deploying-the-model",level:2},{value:"4-6: <strong>Ingesting CSV data for machine learning</strong>",id:"4-6-ingesting-csv-data-for-machine-learning",level:2},{value:"Start the topic",id:"start-the-topic",level:3},{value:"Verify required services are running",id:"verify-required-services-are-running",level:3},{value:"Run extraction",id:"run-extraction",level:3}],d={toc:c};function h(e){let{components:t,...o}=e;return(0,i.kt)("wrapper",(0,a.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"4-1-introduction"},"4-1: ",(0,i.kt)("strong",{parentName:"h2"},"Introduction")),(0,i.kt)("p",null,"The Metric Manager can consume data in four primary ways: Modelling/Mediating\ndata that is in CSV format, Modelling/Mediating data that resides in a database\nvia JDBC connection, and ingesting pre-formed JSON through either the REST\nmediation service or Kafka."),(0,i.kt)("p",null,"This lab will be showing you how to consume data from CSV files. There are CSV\nfiles located in the ",(0,i.kt)("em",{parentName:"p"},"/home/scadmin/BookInfoDemo/data/bookinfo/data")," directory.\nThese files contain metrics for Application response time (APP), CPU utilization\n(CPU), Database transaction volume (DB), and disk utilization (DISKBUSY). This\ndata spans a time period of 17 days."),(0,i.kt)("p",null,"We will create a Metric Manager topic to receive this data, create a model for\nthis data with the Mediation Tool, deploy that model, then start the topic and\nstart ingesting the data."),(0,i.kt)("h2",{id:"4-2-creating-a-topic"},"4-2: ",(0,i.kt)("strong",{parentName:"h2"},"Creating a topic")),(0,i.kt)("p",null,"To create a topic, open a terminal window and run the following commands as user\nscadmin on pi VM:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/scanalytics/analytics/bin\n./admin.sh create_topic BIGBLUE\n")),(0,i.kt)("p",null,"This will take a minute or two while the Metric Manager builds the topic tables\nin the DB2 database and creates the appropriate analytics/streams configuration."),(0,i.kt)("p",null,"Once the ",(0,i.kt)("strong",{parentName:"p"},"create_topic")," command completes, you can list the topics that are\nconfigured on the system by issuing the following command. You should see your\nnew BIGBLUE topic, along with the TEST topic that we created to verify the iFix\ninstall:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh show_topics\nTEST\nBIGBLUE\n")),(0,i.kt)("p",null,"You may delete the TEST topic you created earlier to verify that the update\ncompleted successfully if you wish."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh delete_topic TEST\n")),(0,i.kt)("h2",{id:"4-3-topic-configuration"},"4-3: ",(0,i.kt)("strong",{parentName:"h2"},"Topic configuration")),(0,i.kt)("h3",{id:"topic-configuration-considerations"},"Topic configuration considerations"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Aggregation interval")),(0,i.kt)("p",null,"There are considerations for topic configuration that need to be accounted for\nbased on the data that the Metric Manager will be ingesting. One of the more\nimportant aspects of topic configurations is the system aggregation interval.\nThe aggregation interval defines the rate, in minutes, of the metric data that\nMetric Manager will be consuming. This is largely dictated by the source of the\nmetric data (e.g. an APM tool, network performance monitor, etc). The supported\nPI intervals are 5, 10, 15, and 60 minutes. If the source that is generating\nmetrics for MM ingestion is collecting at 5 minutes, it is best to set the\naggregation interval for the topic to 5. If the metrics are generated at 1\nminute intervals, set the topic to 5 minutes, and PI will automatically\naggregate the data to the 5 minute interval."),(0,i.kt)("p",null,"For 5 minute data, time intervals in minutes/seconds are:"),(0,i.kt)("p",null,"00:00 \u2013 04:59 05:00 \u2013 09:59 10:00 \u2013 14:59 \u2026 \u2026 50:00 \u2013 54:59 55:00 \u2013 55:50"),(0,i.kt)("p",null,"Likewise, 10 minute intervals are:"),(0,i.kt)("p",null,"00:00 \u2013 09:59 10:00 \u2013 19:59 \u2026 \u2026 40:00 - 49:49 50:00 \u2013 59:59"),(0,i.kt)("p",null,"Investigate the data that we will model and ingest. Change your directory to\nwhere our CSV files are located and list the contents of the directory:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd /home/scadmin/BookInfoDemo/data/bookinfo/data\nls\n")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"CSV file naming")),(0,i.kt)("p",null,'You\'ll note that there are a number of csv files in that directory that look to\nadhere to a standard naming convention. There are rules that you must follow for\nnaming these files, and those rules are documented in the "IBM Operations\nAnalytics Predictive Insights" documentation at this link:'),(0,i.kt)("a",{href:"https://www.ibm.com/docs/en/oapi/1.3.6?topic=SSJQQ3_1.3.6/com.ibm.scapi.doc/admin_guide/r_tasp_csvrules.html",target:"_blank"},"Rules for using CSV data sources"),(0,i.kt)("p",null,"In short:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"the file name must start with a group name, and contain a delimiter"),(0,i.kt)("li",{parentName:"ul"},"next, the file name must contain the start date for the data residing in the\ncsv file, and another delimiter"),(0,i.kt)("li",{parentName:"ul"},"the end date is optional if the data that resides in the CSV file is for a\nsingle interval, but if data within the CSV file spans multiple intervals, it\nis required"),(0,i.kt)("li",{parentName:"ul"},"the file name must end in .csv")),(0,i.kt)("p",null,"The files names that we have created for execution of this lab have the format:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"<GROUP>__<STARTDATE>-<STARTTIME>__<ENDDATE>-<ENDTIME>.csv")),(0,i.kt)("p",null,"You will note that some groups have individual daily files (CPU, Diskbusy), and\nothers have one csv file for the entire span of data (APP, DB). The Metric\nManager extraction process is smart enough to read data for each of its\nintervals from the files simply based on the timestamp of the files that exist,\nas well as the timestamps within the files. Since we will be ingesting files in\n'backlog' historical mode, and not live, having daily files or a file that spans\n17 days is fine. If we were ingesting live data for anomaly detection, Metric\nManager would expect to have a single file that contains all metric data for\neach aggregation interval. In live ingestion, the extractor instance will pick\nup the latest file for the previous aggregation interval (e.g. 00:00-04:59) and\nprocess it."),(0,i.kt)("p",null,"So in looking at the file names, we can see that the data in this directory\nstarts at October 1st at midnight, 2020, and ends on October 17th, noon, or\nabout 17 days. Next, let's look at the interval of the data contained in the\nfiles."),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Resources within Metric Manager")),(0,i.kt)("p",null,"Any data sent into Metric Manager (whether it be CSV, or REST/Kafka) must\ncontain enough information to properly classify the component that the metric is\nrelated to. For example, you may be collecting metrics for a router. That router\nmay have multiple interfaces. There are metrics that are applicable to the\nrouter ",(0,i.kt)("strong",{parentName:"p"},"node")," itself (e.g. CPU utilization, buffer utilization), and there are\nmetrics that are applicable to an ",(0,i.kt)("strong",{parentName:"p"},"interface")," on that router (e.g. packet\ndrops, in bits per second, out bits per second, etc)."),(0,i.kt)("p",null,"Run the following command to page through the data contained in the APP file:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"more APP__20201001-0000__20201017-1200.csv\n")),(0,i.kt)("p",null,"Note that the file has the required CSV header, which must be the first entry of\nthe CSV file:"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("em",{parentName:"strong"},"Time,RESOURCE,ResponseTime"))),(0,i.kt)("p",null,"In looking at the file, it's clear that the timestamp is the first column, and\nlooking at the times they are timestamped at 5 minute intervals. Look at the\nother files and confirm that they are also in 5 minute intervals with the\nexception of DISKBUSY, which appear to be in minute intervals. That is fine as\nMM will aggregate our data for us (more on this later)."),(0,i.kt)("p",null,'Also note that the timestamps are in a different format than the file name. It\nis in the format "Day/Month/Year Hour:Minute", using literal slashes, space, and\ncolon as delimiters. Additionally the Year is in 2 digit format, rather than\nfour. So during our model creation, we must use the notation "dd/MM/yy HH:mm".\nIt is important to be cognizant of timestamp formats whether they be in the file\nname, or within the CSV file itself. They may not always be the same, and we\nwill take this into account when we create our model for the CSV data.'),(0,i.kt)("h3",{id:"configuring-topic-options"},"Configuring topic options"),(0,i.kt)("p",null,"Given the velocity of the data contained in these CSV files, we will need to\nconfigure the Metric Manager topic aggregation interval to 5 minutes. To set the\naggregation interval, first check to see what it is currently set to:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/scanalytics/analytics/bin\n./admin.sh show -t=BIGBLUE\n")),(0,i.kt)("p",null,"This will show all of the configurable options for the BIGBLUE topic."),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Note: If the above command does not show an entry for\n'system.aggregation.interval', and only shows a couple of entries, delete the\ntopic and re-create it. There appears to be an environmental problem where the\ntopic sometimes does not get created properly.")),(0,i.kt)("p",null,'The aggregation interval is "system.aggregation.interval". You can see it is\ncurrently set to 15 minutes. To change it to 5 minutes, issue the following\ncommand:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh set -t=BIGBLUE system.aggregation.interval 5\n")),(0,i.kt)("p",null,"To verify the change, run the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh show -t=BIGBLUE |grep system.aggregation.interval\n")),(0,i.kt)("p",null,"... you should see that the system.aggregation.interval property is 5 minutes:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"system.aggregation.interval: 5")),(0,i.kt)("p",null,"When ingesting historical data, it's important to configure the topic such that\nit doesn't automatically delete the data you ingest. Metric Manager is not meant\nto be used as a long-term metric data repository... it is meant to keep the data\nlong enough to successfully identify changes in behavior, and to keep a small\namount of historical for short-term review. By default, a topic's metric data is\ncleared out after 15 days, while anomaly alarm data is kept for 180 days. Since\nwe have data originating from 2020, we need to set a couple more topic\nparameters to ensure the system doesn't age out our data. Set the following\noptions for the topic BIGBLUE:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh set -t=BIGBLUE sta.corr.retention.days 1095\n./admin.sh set -t=BIGBLUE system.alarm.history.retention.days 1095\n./admin.sh set -t=BIGBLUE system.metric.retention.days 1095\n")),(0,i.kt)("p",null,"Another thing you may need to do during a proof of concept is disable alarm\nclearing. This is required to be disabled if you are analyzing past data and\nneed to demonstrate what the anomaly alerts that arrive in Event Manager look\nlike, without having them clear when the anomaly occurrence stops. Since we'll\nbe viewing Event Manager events as part of our labs, we'll disable it:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh set -t=BIGBLUE system.alarm.autoclear false\n")),(0,i.kt)("p",null,"Finally, double-check and verify the topic configuration by running the show\ntopic command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"./admin.sh show -t=BIGBLUE\n")),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(26487).Z,width:"467",height:"648"})),(0,i.kt)("p",null,"Topic configuration is complete!"),(0,i.kt)("h2",{id:"4-4-creating-a-model-to-ingest-csv"},"4-4: ",(0,i.kt)("strong",{parentName:"h2"},"Creating a model to ingest CSV")),(0,i.kt)("p",null,"The Mediation Tool is the component you will use to model the data contained\nwithin the CSV files so that Metric Manager can ingest, process, learn, and\nidentify anomalies within the data. The tool allows you to create a 'model' of\nthe structure of the CSV files you'll be working with, from within a\nuser-friendly Eclipse interface. You can start the Mediation Tool by issuing the\nfollowing commands from your VNC session terminal:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/scanalytics/mediationtool/eclipse\n./eclipse\n")),(0,i.kt)("p",null,'You will be presented with the initial config screen. Leave the default and\nclick "Ok".'),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(75177).Z,width:"816",height:"505"})),(0,i.kt)("p",null,"You will be presented with the main window. In this step we will create a new\nPredictive Insights project. A project is simply a folder that contains one or\nmore model definitions. From the main window select ",(0,i.kt)("strong",{parentName:"p"},"File-",">","New-",">","Project"),"\nfrom the menu bar:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(46794).Z,width:"896",height:"671"})),(0,i.kt)("p",null,"In the next screen, open the ",(0,i.kt)("strong",{parentName:"p"},"Predictive Insights Wizards")," tree, select\n",(0,i.kt)("strong",{parentName:"p"},"Predictive Insights Project"),", and click ",(0,i.kt)("strong",{parentName:"p"},"Next"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(5459).Z,width:"886",height:"662"})),(0,i.kt)("p",null,"The next screen will prompt you for a project name. Enter ",(0,i.kt)("strong",{parentName:"p"},"TECHJAM2022")," and\nclick the ",(0,i.kt)("strong",{parentName:"p"},"Finish")," button."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(80352).Z,width:"885",height:"661"})),(0,i.kt)("p",null,"Next, you will be asked to switch the perspective to Predictive Insights. Click\n",(0,i.kt)("strong",{parentName:"p"},"Yes"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(2863).Z,width:"885",height:"664"})),(0,i.kt)("p",null,"Next, close the welcome screen by clicking on the X in the tab above the text\n",(0,i.kt)("strong",{parentName:"p"},"Welcome to Eclipse"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(99942).Z,width:"887",height:"666"})),(0,i.kt)("p",null,"Finally, you will be in your modelling view. Maximize the window to take up the\nfull screen, you will need the real estate:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(31470).Z,width:"969",height:"717"})),(0,i.kt)("h3",{id:"create-a-data-source"},"Create a data source"),(0,i.kt)("p",null,"Next, we will create a data source. Right click on your ",(0,i.kt)("strong",{parentName:"p"},"TECHJAM2022")," project\nin the navigator, and select ",(0,i.kt)("strong",{parentName:"p"},"New -",">"," Predictive Insights Data Source")),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(5722).Z,width:"1139",height:"1070"})),(0,i.kt)("p",null,"In the dialog window that appears, change the ",(0,i.kt)("strong",{parentName:"p"},"Filename")," parameter to\n",(0,i.kt)("strong",{parentName:"p"},"BIGBLUE.pamodel")," and click ",(0,i.kt)("strong",{parentName:"p"},"Next"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(87250).Z,width:"1067",height:"1093"})),(0,i.kt)("p",null,"In the next screen, you will select ",(0,i.kt)("strong",{parentName:"p"},"File System")," from the drop-down box, and\nselect ",(0,i.kt)("strong",{parentName:"p"},"Metric names in column headers"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(33932).Z,width:"773",height:"797"})),(0,i.kt)("p",null,"Click ",(0,i.kt)("strong",{parentName:"p"},"Finish"),". You now have a data source that we will configure to ingest\nour csv files."),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"A note about CSV structure: CSV files can be in either ",(0,i.kt)("strong",{parentName:"em"},"wide")," or ",(0,i.kt)("strong",{parentName:"em"},"skinny"),"\nformat. ",(0,i.kt)("strong",{parentName:"em"},"Wide")," format specifies the metric name in the CSV header. For\nexample, in our data the CPU group has the following header:")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},'"TIME","RESOURCE","User%","Wait%"')," ",(0,i.kt)("inlineCode",{parentName:"p"},'01/10/20 00:00,"details",84.9,0')," ",(0,i.kt)("inlineCode",{parentName:"p"},"\u2026")," ",(0,i.kt)("inlineCode",{parentName:"p"},"\u2026")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},'Above we can see there are two metric definitions in the csv header, "User%"\nand "Wait%". That indicates that a single CSV line contains multiple metric\ndefinitions per resource. Hence, we selected ',(0,i.kt)("strong",{parentName:"em"},"Metric names in column\nheaders"),".")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"You may come across a situation where the metric name appears in the csv file\ndata rather than the header. Compare the previous example with the following:")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},'"TIME","RESOURCE","METRICNAME"')," ",(0,i.kt)("inlineCode",{parentName:"p"},"01/10/20 03:20,details,User%,84.9"),"\n",(0,i.kt)("inlineCode",{parentName:"p"},"01/10/20 03:20,details,Wait%,0")," ",(0,i.kt)("inlineCode",{parentName:"p"},"\u2026")," ",(0,i.kt)("inlineCode",{parentName:"p"},"\u2026")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},'The CSV contains a generic "METRICNAME" indicator, and the various metric name\nappears within the csv lines, rather than the header. This is ',(0,i.kt)("strong",{parentName:"em"},"skinny")," format,\nand each line contains only one metric. When you model the CSV file, and select\nthe metric column, it will show all of the available unique metric names as\navailable, and you can include/exclude metrics as needed.")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},'Note: If you need to ingest files in both skinny and wide format, you must\ncreate separate data sources for each type, as you cannot match skinny and wide\nformats in a single project. You can deploy multiple CSV data sources to a\nsingle topic, but they must be done as the same deployment action \u2013 that is you\nmust multi-select the data sources, then select "deploy model".')),(0,i.kt)("h3",{id:"configure-the-filesystem-details"},"Configure the filesystem details."),(0,i.kt)("p",null,"The file system details define where the files are located and the structure and\ndate format of the file names."),(0,i.kt)("p",null,"You will be at the following screen:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(12674).Z,width:"968",height:"493"})),(0,i.kt)("p",null,"First, under ",(0,i.kt)("strong",{parentName:"p"},"File System Details"),", change the ",(0,i.kt)("strong",{parentName:"p"},"File Path")," to:"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"/home/scadmin/BookInfoDemo/data/bookinfo/data")),(0,i.kt)("p",null,"This tells the mediation tool where to expect the CSV files."),(0,i.kt)("p",null,"Next, modify the name pattern. As we learned previously, a CSV file name must\nstart with a ",(0,i.kt)("strong",{parentName:"p"},"group reference"),", followed by a ",(0,i.kt)("strong",{parentName:"p"},"delimiter"),", followed next by\na ",(0,i.kt)("strong",{parentName:"p"},"start time")," and an ",(0,i.kt)("strong",{parentName:"p"},"end time")," (with the end time only strictly necessary\nwhen the file contains data for a span of multiple intervals). When defining the\nname pattern, we use regular expressions to match. To keep it simple, use the\nfollowing regex to define the name pattern:"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"(.","*",")","_","_","(.","*",")","_","_","(.","*",")","\\",".csv")),(0,i.kt)("p",null,"The mediation tool, as well as the Metric Manager extractor, uses the first\nregex match as the metric group identifier, the second as the Start Time, and,\nif defined, the third regex match as an end time."),(0,i.kt)("p",null,"Next we will change the time format. The time format uses standard Java time\nformat notation. Looking at our CSV file timestamps, we see that they are\nformatted as such:"),(0,i.kt)("p",null,"20201001-0000"),(0,i.kt)("p",null,"Which, in Java time format notation, is:"),(0,i.kt)("p",null,"yyyyMMdd-HHmm"),(0,i.kt)("p",null,'As such, change the time format to "yyyyMMdd-HHmm"'),(0,i.kt)("p",null,"The files provided are in GMT already so we can leave the timezone as it is."),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Note: It is important to be cognizant of the timezone of the data and configure\nthis appropriately, so that the analytics can properly learn the differences\nbetween weekday and weekend behavior patterns, as well as proper correlation of\nmetrics across all CSV files. In many cases the timezone of the data you work\nwith will be GMT, but you may run into cases where they are provided in some\nlocal time zone. Make sure that you verify with the customer what timezone the\ndata timestamps are in.")),(0,i.kt)("p",null,'Once all the File System Details options have been configured, click the "Test\nMatching". You should get green checkmarks for the files in our directory\nindicating that the name pattern and time format worked properly:'),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(16118).Z,width:"1039",height:"602"})),(0,i.kt)("p",null,"If you see errors indicating 'pattern mismatch', or do not see the green\ncheckmarks, double-check your configuration and try again. If you sill have\ndifficulty consult a lab proctor."),(0,i.kt)("h3",{id:"defining-the-model-from-the-data"},"Defining the model from the data"),(0,i.kt)("p",null,"The next step is to actually build the model from the CSV file structures. Below\nthe ",(0,i.kt)("strong",{parentName:"p"},"File System Details")," window that we just finished configuring and\ntesting, you will see three tabs. Select the ",(0,i.kt)("strong",{parentName:"p"},"Model Design")," tab and click\n",(0,i.kt)("strong",{parentName:"p"},"Ok")," in the dialog window that pops up."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(42755).Z,width:"771",height:"592"})),(0,i.kt)("p",null,"The model design window shows the configured data source (ITM) that we just\nfinished configuring. Right-click on ",(0,i.kt)("strong",{parentName:"p"},"ITM"),", and select ",(0,i.kt)("strong",{parentName:"p"},"Synchronize Schema"),".\nThis will cause the mediation tool to examine the structure and contents of the\nCSV files that match the pattern we defined in the previous section:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(96514).Z,width:"511",height:"700"})),(0,i.kt)("p",null,"The mediation tool will then churn through the available files in our defined\ndirectory, analyze the CSV structure, and present us with the metric groups it\nfound in our directory. In the preview window, select ",(0,i.kt)("strong",{parentName:"p"},"Add New Elements"),", and\nit will select all of the CSV file structures it found in that directory."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(41846).Z,width:"931",height:"555"})),(0,i.kt)("p",null,"select all of the tables and click ",(0,i.kt)("strong",{parentName:"p"},"Ok"),"."),(0,i.kt)("p",null,"Next, for our ITM data source, open up the tree view that is now available:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(63653).Z,width:"816",height:"574"})),(0,i.kt)("p",null,"Expanding the tree view ",(0,i.kt)("strong",{parentName:"p"},"fully")," shows all of the available tables and columns\nin our CSV files.:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(80578).Z,width:"819",height:"1067"})),(0,i.kt)("p",null,"Next, we will create metric groups for each of these. Right-click on ",(0,i.kt)("strong",{parentName:"p"},"APP"),",\nand select ",(0,i.kt)("strong",{parentName:"p"},"New metric group"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(44565).Z,width:"811",height:"290"})),(0,i.kt)("p",null,"You have the option of naming the metric group to anything that is descriptive\nof the type of data in the respective group. In our case, we'll call it\n",(0,i.kt)("strong",{parentName:"p"},"ApplicationPerformance"),", and click ",(0,i.kt)("strong",{parentName:"p"},"Ok"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(67964).Z,width:"933",height:"445"})),(0,i.kt)("p",null,"The next screen will show an attempt by the modelling tool to create a model\nbased on the composition of the CSV header:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(59308).Z,width:"934",height:"481"})),(0,i.kt)("p",null,"The mediation tool did a good job of providing a model based on the structure\nfor this instance. It selected the proper CSV column for the ",(0,i.kt)("strong",{parentName:"p"},"Timestamp\n(Time)"),", the proper CSV column for the ",(0,i.kt)("strong",{parentName:"p"},"Resource Key (RESOURCE)"),", and the\nproper column for the ",(0,i.kt)("strong",{parentName:"p"},"Metric Name (ResponseTime)"),". So in this case, there\nisn't any additional work we need to do to define the model. But we do need to\nconfigure the timestamp format (as we did in the File Details definition). To do\nthis, click select the ",(0,i.kt)("strong",{parentName:"p"},"Model Properties")," tab below the ",(0,i.kt)("strong",{parentName:"p"},"Model Design"),"\nwindow. Open up the ",(0,i.kt)("strong",{parentName:"p"},"Model -",">"," ApplicationPerformance -",">"," Timestamp")," entry,\nand change the ",(0,i.kt)("strong",{parentName:"p"},"Data Type")," to ",(0,i.kt)("strong",{parentName:"p"},"String")," if it isn't already."),(0,i.kt)("p",null,"Recall our earlier examination of the CSV file content. We discovered that the\ntime format of the timestamp within the CSV file is different that it is in the\nfilename. As such we must define ",(0,i.kt)("strong",{parentName:"p"},"Time Format")," as ",(0,i.kt)("strong",{parentName:"p"},"dd/MM/yy HH:mm")," (don't\nforget the space between the date and time). When you are finished entering the\nTime Format field, hit the ",(0,i.kt)("strong",{parentName:"p"},"enter")," key so that the entry is saved."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(95830).Z,width:"934",height:"238"})),(0,i.kt)("p",null,"Finally, click on the ",(0,i.kt)("strong",{parentName:"p"},"Model Design")," tab to return to the model design window,\nand click on the ",(0,i.kt)("strong",{parentName:"p"},"preview data")," icon to verify that the model is working:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(57501).Z,width:"934",height:"75"})),(0,i.kt)("p",null,"You should see a preview of the data extraction in the ",(0,i.kt)("strong",{parentName:"p"},"Data Extraction\nPreview")," tab:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(12012).Z,width:"933",height:"515"})),(0,i.kt)("p",null,"If you do not see data in the preview after clicking on the ",(0,i.kt)("strong",{parentName:"p"},"Preview\nextraction")," icon, verify the configuration of your timestamp in the model\nproperties tab. If you feel you have verified everything and are still having\nissues, consult a lab proctor."),(0,i.kt)("p",null,"Finally, take a moment to save the work we have done so far for modelling the\ncsv data in case we should lose connection or some other unavoidable disaster\noccurs. In the Menu, select ",(0,i.kt)("strong",{parentName:"p"},"File -",">"," Save"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(16474).Z,width:"932",height:"589"})),(0,i.kt)("p",null,"Next, we will configure a model for the ",(0,i.kt)("strong",{parentName:"p"},"CPU")," data. From the ",(0,i.kt)("strong",{parentName:"p"},"Model Design"),"\nwindow, right-click on ",(0,i.kt)("strong",{parentName:"p"},"CPU")," under the ITM data source, and select ",(0,i.kt)("strong",{parentName:"p"},"New\nMetric Group"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(58369).Z,width:"792",height:"264"})),(0,i.kt)("p",null,"Name the metric group ",(0,i.kt)("strong",{parentName:"p"},"CpuUtilization"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(25787).Z,width:"933",height:"442"})),(0,i.kt)("p",null,"Again, we see that the mediation tool did a good job of identifying which CSV\ncolumns should be used for the timestamp, resource, and even identified that\nthere are two metric columns in the file:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(33632).Z,width:"934",height:"437"})),(0,i.kt)("p",null,"So next, define the timestamp format by selecting the ",(0,i.kt)("strong",{parentName:"p"},"Model Properties")," tab,\nopening up the ",(0,i.kt)("strong",{parentName:"p"},"CpuUtilization")," model definition, selecting ",(0,i.kt)("strong",{parentName:"p"},"Timestamp"),", and\nselecting ",(0,i.kt)("strong",{parentName:"p"},"String")," as the Data Type and entering ",(0,i.kt)("strong",{parentName:"p"},"dd/MM/yy HH:mm")," for the\ntime format, ensuring to hit ",(0,i.kt)("strong",{parentName:"p"},"Enter")," when done typing in the time format."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(99686).Z,width:"935",height:"218"})),(0,i.kt)("p",null,"Return to the ",(0,i.kt)("strong",{parentName:"p"},"Model Design")," tab and test the model design by clicking on the\n",(0,i.kt)("strong",{parentName:"p"},"preview extraction")," button."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(29003).Z,width:"934",height:"75"})),(0,i.kt)("p",null,"Verify data in extraction preview:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(10348).Z,width:"936",height:"487"})),(0,i.kt)("p",null,"Ensure that you have both metrics ",(0,i.kt)("strong",{parentName:"p"},"User%")," and ",(0,i.kt)("strong",{parentName:"p"},"Wait%")," in the preview."),(0,i.kt)("p",null,"Again, save your model progress by clicking on"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"File -",">"," Save")),(0,i.kt)("p",null,'Next, create a metric group for database data. Right-click on "DB" and select\n"New Metric Group":'),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(55117).Z,width:"806",height:"356"})),(0,i.kt)("p",null,"Call your metric group ",(0,i.kt)("strong",{parentName:"p"},"DatabasePerformance")," and click ",(0,i.kt)("strong",{parentName:"p"},"Ok"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(26163).Z,width:"935",height:"443"})),(0,i.kt)("p",null,"As with the previous two groups, we again see that the mediation tool has done a\ngood job of classifying which fields are the timestamp, resource, and metric."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(49856).Z,width:"934",height:"387"})),(0,i.kt)("p",null,"Define your timestamp format in Model Properties tab, making sure you select the\ntimestamp definition under ",(0,i.kt)("strong",{parentName:"p"},"DatabasePerformance"),", setting it to ",(0,i.kt)("strong",{parentName:"p"},"dd/MM/yy\nHH:mm"),"."),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(1122).Z,width:"935",height:"235"})),(0,i.kt)("p",null,"Again, return to the Model Design tab and click on the extraction preview icon\nto preview the extraction:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(9234).Z,width:"934",height:"502"})),(0,i.kt)("p",null,"Save the model progress by selecting"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"File -",">"," Save")),(0,i.kt)("p",null,'Lastly, we will model the DISKBUSY csv. Right-click on DISKBUSY under the ITM\ndata source, and select "New Metric Group":'),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(97290).Z,width:"801",height:"271"})),(0,i.kt)("p",null,"Call the metric group ",(0,i.kt)("strong",{parentName:"p"},"DiskPerformance")),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(46189).Z,width:"934",height:"441"})),(0,i.kt)("p",null,"Review the model definition:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(67261).Z,width:"933",height:"373"})),(0,i.kt)("p",null,"Note that in the CSV file, we have four columns: TIME, RESOURCE, DISKNAME, and\nDISKBUSY. The mediation tool did a good jo of defining the Timestamp and\nidentifying the metric name. However, for the resource key, it only used the\nRESOURCE field in the CSV file. If we don't add the DISKNAME field to the\nresource key, the Metric Manager will just aggregate/average the data for all\ndisks to a single metric (DISKBUSY) at the Node level, which is certainly not\nwhat we want."),(0,i.kt)("p",null,"The resource key is important for metrics that may be specific to a component or\nset of components on a node or device. For example, if Metric Manager is\nreceiving network utilization metrics from a server that has ",(0,i.kt)("strong",{parentName:"p"},"2 network\ninterface cards"),", you need to define the resource not as simply the Node, but\nthe ",(0,i.kt)("strong",{parentName:"p"},"Node + network interface card name"),'\u2026 e.g. "server1:eth0 and\nserver1:eth1".'),(0,i.kt)("p",null,"The mediation tool does this for us when we define multiple columns as the\n",(0,i.kt)("strong",{parentName:"p"},"Resource Key"),"."),(0,i.kt)("p",null,"In our case, what we need to do is include the ",(0,i.kt)("strong",{parentName:"p"},"DISKNAME")," as part of the\nResource Key, so we don't just aggregate/average all values for all disks at the\nNode level. To do this, select ",(0,i.kt)("strong",{parentName:"p"},"DISKNAME")," from the ITM data tree with the left\nmouse button, hold down the button and drag it into the Attributes window to add\nDISKNAME as an attribute. Alternatively you can right-click on ",(0,i.kt)("strong",{parentName:"p"},"DISKNAME")," and\nselect ",(0,i.kt)("strong",{parentName:"p"},"Add Attribute"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(39468).Z,width:"934",height:"619"})),(0,i.kt)("p",null,"You'll notice that it automatically gives it ",(0,i.kt)("strong",{parentName:"p"},"Application")," as an Attribute\nname. You can leave it as is or change it to ",(0,i.kt)("strong",{parentName:"p"},"Disk")," or something descriptive\nif you wish."),(0,i.kt)("p",null,"Next, repeat the same process to add the DISKNAME field to the resource key. In\nthe ITM data tree, select ",(0,i.kt)("strong",{parentName:"p"},"DISKNAME")," with your left mouse button, hold down\nthe button and drag it to the Resource Key. Alternatively you can right-click on\nDISKNAME and select ",(0,i.kt)("strong",{parentName:"p"},"Add Resource Key"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(61738).Z,width:"934",height:"547"})),(0,i.kt)("p",null,"Finally, go to the ",(0,i.kt)("strong",{parentName:"p"},"Model Properties")," tab and define the timestamp format as\n",(0,i.kt)("strong",{parentName:"p"},"dd/MM/yy HH:mm"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(73868).Z,width:"934",height:"453"})),(0,i.kt)("p",null,"Return to the ",(0,i.kt)("strong",{parentName:"p"},"Model Design")," tab and click on the ",(0,i.kt)("strong",{parentName:"p"},"preview extraction")," icon.\nA Warning window will pop up:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(109).Z,width:"933",height:"623"})),(0,i.kt)("p",null,"What this is telling us is that there are multiple entries for values in each\ntime interval defined in the file."),(0,i.kt)("p",null,"This could be a data quality issue. Minimize the mediation utility and open up a\nnew terminal window, and issue the following commands:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd /home/scadmin/BookInfoDemo/data/bookinfo/data\ncat DISKBUSY__20201001-0000__20201002-0000.csv |head -n 20\n")),(0,i.kt)("p",null,"You'll notice that indeed there are multiple entries for a given time stamp."),(0,i.kt)("p",null,"If this were a data quality issue, it may be due to the exclusion of another\ncomponent from the csv file that would make the resource more unique, that would\nbe needed to be included in the resource key. Or perhaps there is something not\nright with how the data is being extracted and written."),(0,i.kt)("p",null,"In our case, upon further investigation and a discussion with the team that\nmanages the tool that measures DIKSBUSY, we discover the DISKBUSY metric is\nmeasured and written every 10 seconds, but the time format as written has left\noff the seconds column. This isn't a problem in this case, because the smallest\naggregation interval Metric Manager supports is 5 minutes, and these values will\nbe all aggregated up to 5 minutes anyway\u2026 even if the seconds column were\nincluded. So in our case, we can safely ignore the error."),(0,i.kt)("p",null,"Data quality is paramount to ensure maximum value from Metric Manager. Be aware\nof the format of the data, and if there is something you come across that\ndoesn't seem right, consult the owners of the tool that's generating the data\nfor Metric Manager and verify that it is correct."),(0,i.kt)("p",null,"To continue the lab, return to the Mediation Tool window and click ",(0,i.kt)("strong",{parentName:"p"},"Ok")," and\nverify that your extraction preview shows data:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(79504).Z,width:"935",height:"463"})),(0,i.kt)("p",null,'Now that we have completed the data modelling, we are ready to "Deploy" our\nmodel to the BIGBLUE topic that we created earlier. Before doing that, select'),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"File -",">"," Save")),(0,i.kt)("p",null,"To save the model:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(42694).Z,width:"934",height:"589"})),(0,i.kt)("h2",{id:"4-5-deploying-the-model"},"4-5: Deploying the model"),(0,i.kt)("p",null,"Next, to deploy the model, right-click on the BIGBLUE.pamodel title under the\nTECHJAM2022 project, and select ",(0,i.kt)("strong",{parentName:"p"},"Deploy Model"),":"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(39462).Z,width:"965",height:"1065"})),(0,i.kt)("p",null,"And change the following items in the configuration window:"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"JDBC URL: jdbc:db2://pi-template.Hybrid-Squad.cloud:50000/SCAPIDB")," ",(0,i.kt)("inlineCode",{parentName:"p"},"Password:"),"\n",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">")),"\n",(0,i.kt)("inlineCode",{parentName:"p"},'<CHECK "Save as Project Defaults">')),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(80242).Z,width:"636",height:"445"})),(0,i.kt)("p",null,"Click ",(0,i.kt)("strong",{parentName:"p"},"Ok")," when finished:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(81479).Z,width:"931",height:"564"})),(0,i.kt)("p",null,'If there are multiple topics configured in the Metric Manager install, you will\nneed to select the appropriate topic from the drop-down list. Select "BIGBLUE"\nand click "Ok":'),(0,i.kt)("p",null,"If there is just a single topic, it will deploy straight away."),(0,i.kt)("p",null,"After the KPI count is complete, click ",(0,i.kt)("strong",{parentName:"p"},"Yes")," to deploy the model to the topic:"),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(61391).Z,width:"935",height:"407"})),(0,i.kt)("p",null,"After the deployment completes successfully, exit the mediation tool to return\nto the command line."),(0,i.kt)("h2",{id:"4-6-ingesting-csv-data-for-machine-learning"},"4-6: ",(0,i.kt)("strong",{parentName:"h2"},"Ingesting CSV data for machine learning")),(0,i.kt)("h3",{id:"start-the-topic"},"Start the topic"),(0,i.kt)("p",null,"Now that we have successfully created and deployed a model to our topic, we can\nextract the data for analysis and see how the Metric Manager learns the behavior\nof the data and identifies situations where the data has acted contrary to the\nlearned behavior. We must first start the topic. Exit the mediation tool to\nreturn to the command line and run the following command to start the topic:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/start.sh -t=BIGBLUE\n")),(0,i.kt)("p",null,"After about 2 minutes you should see a message indicating that the topic is\nrunning:"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"}," ",(0,i.kt)("strong",{parentName:"em"},"Instance AnalyticsBIGBLUE running")," ")),(0,i.kt)("p",null,"If you see an error message, rather than the above message, try stopping the\nStreams instance, and then start the topic using the following commands:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/stop.sh -s\n/opt/IBM/scanalytics/analytics/bin/start.sh -t=BIGBLUE\n")),(0,i.kt)("p",null,"If you still have problems starting up the topic, ask a lab proctor for\nassistance."),(0,i.kt)("h3",{id:"verify-required-services-are-running"},"Verify required services are running"),(0,i.kt)("p",null,"Before we start the extraction, verify that the Netcool services are up and\nrunning by issuing the following command, using the password ",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">"))," as the password:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"sudo systemctl status nco\n")),(0,i.kt)("p",null,"The Active line should say active. If it is not showing an active status, start\nit up by running:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"sudo systemctl stop nco\nsudo systemctl start nco\n")),(0,i.kt)("p",null,"Next verify the Netcool GUI is up and running by issuing the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"sudo systemctl status netcoolwebgui\n")),(0,i.kt)("p",null,'If the "Active" line is showing any status other than "active (exited)", start\nit up by running:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"sudo systemctl stop netcoolwebgui\nsudo systemctl start netcoolwebgui\n")),(0,i.kt)("p",null,"Ensure that the DB2 database is running by running:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"db2pd -\n")),(0,i.kt)("p",null,'The "Database Member 0" should show active. If it is not active, start DB2 by\nrunning:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"db2start\n")),(0,i.kt)("p",null,"Finally, verify that the Metric Manager UI is running by issuing the following\ncommand:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/UI/bin/pi.sh -status\n")),(0,i.kt)("p",null,"If the IBM Websphere Liberty Profile is DOWN, run the following command to start\nit:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/UI/bin/pi.sh -start\n")),(0,i.kt)("p",null,"and verify the status again to ensure the profile is UP."),(0,i.kt)("h3",{id:"run-extraction"},"Run extraction"),(0,i.kt)("p",null,"Once the Netcool core, Web GUI, DB2, and Metric Manager UI components are\nrunning, we are ready to extract the data. Run the following command to start\nextraction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"$PI_HOME/bin/admin.sh run_extractor_instance -t=BIGBLUE -s=20201001-0000 -e=20201017-1200\n")),(0,i.kt)("p",null,"This will initiate the ingestion process, and start the extraction from October\n1st, 2020 at midnight, and end the extraction when it has ingested data all the\nway up to October 17"),(0,i.kt)("p",null,"To monitor the ingestion,"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"cd ~/BookInfoDemo/data/bookinfo/data\nls\n")),(0,i.kt)("p",null,"If you list the directory, you will see as the ingestion process proceeds, files\nthat are being read are changed to prepend the filename to INUSE.\\<filename",">"," a\nsuch:"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"INUSE.DISKBUSY","_","_","20201002-0000","_","_","20201003-0000.csv")),(0,i.kt)("p",null,"Next, list the files in the 'good' directory. You will see files that have\ncompleted ingestion arrive in the 'good' directory."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sh"},"ls good\n")),(0,i.kt)("p",null,"By watching both the data directory and the good directory, you will be able to\nsee which files are being processed (INUSE), and which files are complete and\nend up in the 'good' directory."),(0,i.kt)("p",null,"Take a break. In about 12 to 15 minutes, the data directory will be empty of all\nCSV files, which have been moved to the good directory. Machine learning and\nanomaly detection of the ingested data will complete. The next lab will walk\nthrough navigating the UI and viewing the results."))}h.isMDXComponent=!0},26487:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture1-e81ff71925efa44fe1a7e464299bb469.png"},87250:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture10-451c2773fbad8c7ea512fa0ce03bab6b.png"},33932:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture11-4aeacdbafda62c07e928359cb20dc7d1.png"},12674:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture12-01002c1712d97a5302c30458d306469c.png"},16118:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture13-2eea9a4fe65fc2cb63e4633af1be5cc4.png"},42755:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture14-b93b04d02c4a348071e15401460d1f4e.png"},96514:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture15-f5eafc63207cfad4a4a5d4d7981fa5ab.png"},41846:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture16-4b53a42545a47e9e3e89178775cf1c9c.png"},63653:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture17-7c858fe03e69322a0b6c9c2bcd748fe2.png"},80578:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture18-2442c41fab06487e3e9b53c0c8614c03.png"},44565:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture19-5c57abc16271dd9002b99bf8de8c20b8.png"},75177:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture2-a53edb11b6dc3fe5dc0dc03a2c300b90.png"},67964:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture20-a203a5a3b9ffd98bdee56b7d00bcfa91.png"},59308:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture21-cb2a18aaf842cf64064717bc3385b1c0.png"},95830:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture22-a2835720e6f9c8c2e040cd3d7ef6a998.png"},57501:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture23-5be9c0e5fc02a79c5ef9a5d272aed325.png"},12012:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture24-641f6be211d52a4212e6c9777c367e41.png"},16474:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture25-b4afd0e399ac425cac01492a4a49cc68.png"},58369:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture26-838ab75ee75f89f3e420d6b6cc1e950b.png"},25787:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture27-4baef6c524fb1c97457b77fd38208bc2.png"},33632:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture28-6f281999927fa49797beaf60e2347e16.png"},99686:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture29-b389a79baca2c2333726d5383fa4bce9.png"},46794:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture3-34dee0badfe331e4a94d2118ed79d41c.png"},29003:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture30-e60dbd2e188f5339517dbd3684545370.png"},10348:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture31-73e0181e2c410d99776a56e5f3401e4c.png"},55117:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture32-e2a9d3024d890827308a1d2c46884211.png"},26163:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture33-c53e56d618442373aa66d8a4a31156a7.png"},49856:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture34-cfa0e360820fdd28665b8a372ec417d7.png"},1122:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture35-47132ea1d0fd84c390ecb551d645bd01.png"},9234:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture36-bd85cd0959431051f0b736dbb651d0e6.png"},97290:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture37-c563943413092f997a6cfa78e74b9d60.png"},46189:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture38-6dd2912e982ea819bc7fe72eb837d369.png"},67261:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture39-92d5031107887d5d45e7b06dcd3d23a1.png"},5459:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture4-a61696bd991cc17b4f576be2d6126ad8.png"},39468:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture40-563f07e050e921727287dde487cff967.png"},61738:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture41-ac5f8f62563596d51b7aba23c32f8561.png"},73868:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture42-768f8f95668920db724d8044407cbe90.png"},109:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture43-c98818e113b3ab2aa871ffda381099fb.png"},79504:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture44-88b68bffbceac8b991b6ad4d72de75da.png"},42694:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture45-4190038b3b6f302141db3f0d6576ce74.png"},39462:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture46-3913a9ea45f355a57068ec744e45d626.png"},81479:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture47-238e75642bb295d5117131327747d8e6.png"},61391:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture48-eafccb8dc76909df79eca42294b1eda7.png"},80352:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture5-b9fba799b84c5942b9ffc8ef5e2fe2a7.png"},2863:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture6-c6d1d13e3b058427c8ed33ef71e83dea.png"},99942:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture7-3a7eb710eb9d1aafeea03acb617c75b1.png"},31470:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture8-8b6b116da283942647492463de9fde58.png"},5722:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Picture9-9bc93866f1f8327c49caf96a8218b853.png"},80242:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/lab3-addon1-c1d6ac30171df72a2068366cd99ad8eb.png"}}]);