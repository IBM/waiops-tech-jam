"use strict";(self.webpackChunkswat_hub=self.webpackChunkswat_hub||[]).push([[7022],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=c(a),h=r,m=u["".concat(l,".").concat(h)]||u[h]||d[h]||s;return a?n.createElement(m,i(i({ref:t},p),{},{components:a})):n.createElement(m,i({ref:t},p))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,i=new Array(s);i[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var c=2;c<s;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},88140:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var n=a(87462),r=(a(67294),a(3905));const s={title:"6. REST Data Mediation",description:"This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager",sidebar_position:6},i=void 0,o={unversionedId:"metric-management/mm-mediating-rest/index",id:"metric-management/mm-mediating-rest/index",title:"6. REST Data Mediation",description:"This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager",source:"@site/labs/metric-management/6-mm-mediating-rest/index.mdx",sourceDirName:"metric-management/6-mm-mediating-rest",slug:"/metric-management/mm-mediating-rest/",permalink:"/waiops-tech-jam/labs/metric-management/mm-mediating-rest/",draft:!1,editUrl:"https://github.com/IBM/waiops-tech-jam/labs/metric-management/6-mm-mediating-rest/index.mdx",tags:[],version:"current",sidebarPosition:6,frontMatter:{title:"6. REST Data Mediation",description:"This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"5. Reviewing Ingestion Results",permalink:"/waiops-tech-jam/labs/metric-management/mm-analyzing-results/"},next:{title:"7. Metric Anomaly Detection",permalink:"/waiops-tech-jam/labs/metric-management/mm-mad/"}},l={},c=[{value:"6-1: Lab Introduction",id:"6-1-lab-introduction",level:2},{value:"6-2: Starting Cassandra",id:"6-2-starting-cassandra",level:2},{value:"Configuring startup:<br/>",id:"configuring-startup",level:3},{value:"Configure Cassandra with a username and password",id:"configure-cassandra-with-a-username-and-password",level:3},{value:"6-3: Create a topic for REST data",id:"6-3-create-a-topic-for-rest-data",level:2},{value:"Modify the topic to extract data from Cassandra:",id:"modify-the-topic-to-extract-data-from-cassandra",level:3},{value:"6-4: Configuring the REST mediation service",id:"6-4-configuring-the-rest-mediation-service",level:2},{value:"Configuring authentication for the REST mediation service",id:"configuring-authentication-for-the-rest-mediation-service",level:3},{value:"6-5: Starting Kafka",id:"6-5-starting-kafka",level:2},{value:"6-6: Starting Spark",id:"6-6-starting-spark",level:2},{value:"6-7: Starting the REST mediation service",id:"6-7-starting-the-rest-mediation-service",level:2},{value:"6-8: Send data to the REST interface:",id:"6-8-send-data-to-the-rest-interface",level:2}],p={toc:c};function d(e){let{components:t,...s}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"6-1-lab-introduction"},"6-1: Lab Introduction"),(0,r.kt)("p",null,"In lab 3 we created a model for metric data that resided in CSV files. Metric\nManager can also ingest data via a REST interface. The REST interface can accept\npre-defined JSON payloads and process them for analysis and machine learning."),(0,r.kt)("p",null,"Since the definition of the JSON payload describes the model within its\nstructure, it is not required to use the Mediation Tool to create a model. The\npre-defined JSON format defines the model, and it is only necessary to ensure\nthat the JSON payload adheres to the required format. This format is also the\nsame as the new version of Watson AIOps container-based Metric Anomaly Detection\ncomponent that is being actively developed, which we will be working with in the\nfinal lab."),(0,r.kt)("p",null,"This lab will go through the various components that make up the REST mediation\nservice. We will configure the components that we installed in lab 1, start the\nmediation service, and use a simple script to send data to the REST mediation\nservice, and view the results."),(0,r.kt)("h2",{id:"6-2-starting-cassandra"},"6-2: Starting Cassandra"),(0,r.kt)("p",null,'Data that is sent to the REST mediation service is stored in a Cassandra\ndatabase. The "run_extractor_instance" command will pull metrics from Cassandra\nfor analysis. For production deployments, and depending on metric load, it is\npossible to use a distributed installation of Cassandra for high availability\nand performance. For this lab we will be configuring a single Cassandra\ninstance.'),(0,r.kt)("h3",{id:"configuring-startup"},"Configuring startup:",(0,r.kt)("br",null)),(0,r.kt)("hr",null),(0,r.kt)("p",null,"As the 'scadmin' user, start Cassandra with the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\n")),(0,r.kt)("p",null,"Run the following command to verify that Cassandra is running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"ps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\n")),(0,r.kt)("p",null,"Next, using your preferred text editing tool, edit the\n/opt/IBM/apache-cassandra-3.11.10/bin/stop-server script and add the following\nline to the end of the file:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"pgrep -u $(whoami) -f cassandra | xargs -t -i kill {}")),(0,r.kt)("p",null,"Run the 'stop-server' command to stop the Cassandra server:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\n")),(0,r.kt)("p",null,"And ensure the stop script stopped Cassandra:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"ps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\n")),(0,r.kt)("p",null,"Clean up the Cassandra data folder:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/apache-cassandra-3.11.10/data/data/\nrm -rf system\n")),(0,r.kt)("p",null,"Start Cassandra:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\n")),(0,r.kt)("p",null,"List the Cassandra servers:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\n")),(0,r.kt)("p",null,"You should see a response similar to the following, indicating that it is\nlistening 127.0.0.1:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"UN 127.0.0.1 133.29 KiB 256 100.0% b2f89d8c-dd23-451c-907a-59b72dc4d18c rack1")),(0,r.kt)("h3",{id:"configure-cassandra-with-a-username-and-password"},"Configure Cassandra with a username and password"),(0,r.kt)("p",null,"For security, it is required to configure Cassandra with a username and password\nso the topic extractor can securely authenticate with Cassandra and extract\nmetric data. Using your preferred text editor, edit the\n/opt/IBM/apache-cassandra-3.11.10/conf/cassandra.yaml and change the\n",(0,r.kt)("strong",{parentName:"p"},"authenticator")," line to:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"authenticator: PasswordAuthenticator")),(0,r.kt)("p",null,"Save the file and restart Cassandra:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\n/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\n")),(0,r.kt)("p",null,"Finally, verify password authentication is working by running cqlsh, passing in\nusername and ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<CASSANDRA DEFAULT\nPASSWORD",">"))," as the password."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <DEFAULT CASSANDRA PASSWORD>\n")),(0,r.kt)("p",null,"You should see a successful connect, and arrive at the cqlsh prompt."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"cassandra@cqlsh>")),(0,r.kt)("p",null,"Use the following commands to change the default 'cassandra' user's password to\neither the ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<CASSANDRA PASSWORD",">")),"\nprovided by the lab proctor, or the cassandra password you chose if you were\nrequired to use an alternative:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cassandra@cqlsh> alter user cassandra with password '<CASSANDRA PASSWORD>';\ncassandra@cqlsh> quit\n")),(0,r.kt)("p",null,"Encrypt and copy the default Cassandra password using the following commands.\nWhen prompted, enter <CASSANDRA PASSWORD",">"," as the password:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/admin.sh passwd -c $PI_HOME/config/cassandra.properties connection.password\n")),(0,r.kt)("p",null,"Inspect the encrypted password in the following file using the following\ncommand:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cat $PI_HOME/config/cassandra.properties\n")),(0,r.kt)("h1",{id:"-danger-will-robinson--"},(0,r.kt)("strong",{parentName:"h1"},"!!! DANGER WILL ROBINSON !!! ")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},' !! NOTE !!: If the encrypted Cassandra password you inspected in the previous\ncommand begins with the "+" character, you will need to select an alternative\npassword for the Cassandra \'cassandra\' user. This is due to a current defect in\nthe REST mediation code. Try making up an alternative password of your choice,\nencrypt it, and if it doesn\'t begin with a "+" character, use your chosen\npassword an alternative. Then, in the next section, use your alternative\npassword in place of <CASSANDRA PASSWORD',">"," ")),(0,r.kt)("h2",{id:"6-3-create-a-topic-for-rest-data"},"6-3: Create a topic for REST data"),(0,r.kt)("p",null,"You can store metric data data derived from REST only in the topic that you use\nto extract the REST Mediation Service data. You cannot use an existing topic if\nit contains data from a CSV file or database. However, you can use an existing\ntopic if it does not contain any data or if it contains only JSON data. We will\nreconfigure our BIGBLUE topic to accept REST data."),(0,r.kt)("p",null,'Return to a terminal window and clear the topic using the following commands.\nWhen prompted, type " ',(0,r.kt)("strong",{parentName:"p"},'I am sure"'),' and press enter. When it asks whether you\nwant to clear out the database, type " ',(0,r.kt)("strong",{parentName:"p"},"Yes"),'" and press enter. This will clean\nout all of the data from the topic and reset it to pristine.'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/stop.sh -s\n/opt/IBM/scanalytics/analytics/bin/admin.sh cleanup -t=BIGBLUE\n")),(0,r.kt)("h3",{id:"modify-the-topic-to-extract-data-from-cassandra"},"Modify the topic to extract data from Cassandra:"),(0,r.kt)("p",null,"The following command configures the topic to connect to cassandra on localhost:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.host localhost\n")),(0,r.kt)("p",null,"Obtain the encrypted cassandra password, copying the text that follows\n",(0,r.kt)("strong",{parentName:"p"},"cassandra.password=")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cat $PI_HOME/config/cassandra.properties\n")),(0,r.kt)("p",null,"Set the encrypted value for our BIGBLUE topic, pasting the value for\n'connection.password' obtained from the previous output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.password <ENCRYPTED CASSANDRA PASSWORD>\n")),(0,r.kt)("p",null,"Set the Cassandra user for the topic to 'cassandra':"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.username cassandra\n")),(0,r.kt)("h2",{id:"6-4-configuring-the-rest-mediation-service"},"6-4: Configuring the REST mediation service"),(0,r.kt)("p",null,"The next step in configuring the REST integration requires configuring the REST\nmediation service mediation configuration files. We will encrypt the Cassandra\npassword and store it in the Mediation Service yaml files. We will use the user\n'piadmin' to encrypt the password, then update the appropriate mediation service\nyaml files. The reason we need to use a separate user is because we require Java\n11 for the IBM REST mediation code itself, while the rest of the REST mediation\ncomponents (Cassandra, spark, kafka) requires Java 8."),(0,r.kt)("p",null,"Sudo to the 'piadmin' user, using the password ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">"))," and run the password\nencryption utility, passing ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<CASSANDRA\nPASSWORD",">"))," as the argument to the encrypt_password.sh command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"sudo su - piadmin\ncd /opt/IBM/pi-mediation-1.0.4\n./encrypt_password.sh <CASSANDRA PASSWORD>\n")),(0,r.kt)("p",null,'The "encrypt_password.sh" tool will print the encrypted password. Copy the\nencrypted password.'),(0,r.kt)("p",null,'Using your preferred text editor, edit the\n/opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and modify the\n"cassandra.encrypted.password:" entry, paste the encrypted password text.'),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>")),(0,r.kt)("p",null,"Save the file and exit."),(0,r.kt)("p",null,"Next, edit the /opt/IBM/pi-mediation-1.0.4/config/metric-spark.yml file and\nmodify the following entries in the file:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"spark.cassandra.auth.username: cassandra"),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"spark.cassandra.auth.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>"),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"cassandra.username: cassandra"),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>")),(0,r.kt)("p",null,"Save the file and exit."),(0,r.kt)("h3",{id:"configuring-authentication-for-the-rest-mediation-service"},"Configuring authentication for the REST mediation service"),(0,r.kt)("p",null,"The REST API requires that you set a password to ensure that connections are\nauthenticated. We will use the password ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB\nPASSWORD",">"))," as our API password. As the piadmin user, encrypt the\npassword, making sure to substitute ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB\nPASSWORD",">"))," with the lab password provided earlier:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/pi-mediation-1.0.4/\n./encrypt_password.sh <LAB PASSWORD>\n")),(0,r.kt)("p",null,"Copy the encrypted password."),(0,r.kt)("p",null,"Once you have obtained and copied the encrypted password for the REST service,\nedit the \"/opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and\nmodify the entry 'metrics.api.encrypted.password' entry, pasting the encrypted\npassword."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"metrics.api.encrypted.password: <ENCRYPTED LAB PASSWORD>")),(0,r.kt)("h2",{id:"6-5-starting-kafka"},"6-5: Starting Kafka"),(0,r.kt)("p",null,"Copy the startup script for Kafka to the kafka directory, then run the script to\nstart kafka:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cp /home/piadmin/start-pi-kafka.sh /opt/IBM/kafka_2.13-2.6.2/\n/opt/IBM/kafka_2.13-2.6.2/start-pi-kafka.sh\n")),(0,r.kt)("p",null,"Wait about 30 seconds, then verify that it is running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"ps -ef |grep kafka.Kafka |grep -v grep\n")),(0,r.kt)("h2",{id:"6-6-starting-spark"},"6-6: Starting Spark"),(0,r.kt)("p",null,"Spark must be run as the 'piadmin' user. Start the Spark services by running the\nfollowing command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/spark-3.1.2-bin-hadoop3.2/sbin/start-all.sh\n")),(0,r.kt)("p",null,"Use ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">"))," for the password\nif it prompts."),(0,r.kt)("h2",{id:"6-7-starting-the-rest-mediation-service"},"6-7: Starting the REST mediation service"),(0,r.kt)("p",null,"Become the piadmin user (if you're not already) and start the service. The\nservice must be started from within the mediation directory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cd /opt/IBM/pi-mediation-1.0.4/\n./run_service.sh\n")),(0,r.kt)("p",null,"Next, verify that the mediation service is running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"ps -ef |grep yml\n")),(0,r.kt)("p",null,"You should see the following two java processes running:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"java -Xms1G -Xmx2G -jar libs/ea-metric-spark.jar server config/metric-spark.yml"),(0,r.kt)("br",null),"\n",(0,r.kt)("inlineCode",{parentName:"p"},"java -Xms1G -Xmx2G -jar libs/ea-metric-api.jar server config/metric-api-service.yml")),(0,r.kt)("h2",{id:"6-8-send-data-to-the-rest-interface"},"6-8: Send data to the REST interface:"),(0,r.kt)("p",null,"If you are still the 'piadmin' user, exit back to the 'scadmin' user, or open a\nnew terminal window. We will be using secure copy to obtain a JSON file that\ncontains metrics that we will be sending to the REST service. Run the following\ncommands as the scadmin user to obtain the file. :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"cd /home/scadmin/BookInfoDemo/data/bookinfo\nwget http://150.238.93.118/BookInfoJson-20220721-0000__20220806-1200.json\n")),(0,r.kt)("p",null,"When the file transfer completes, you can use curl to send the data to the REST\nservice. Execute the following commands to send JSON data to the Metric Manager\nREST mediation service, making sure to substiture ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">")),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},'curl -vX POST --user "system:<LAB PASSWORD>" --header "Content-Type: application/json" --header "X-TenantID: BIGBLUE" http://pi-template.Hybrid-Squad.cloud:18080/metrics/api/1.0/metrics -d @BookInfoJson-20220721-0000__20220806-1200.json\n')),(0,r.kt)("p",null,"The key response lines that you will see when the load is successful are:"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"< HTTP/1.1 100 Continue"),(0,r.kt)("br",null)," ",(0,r.kt)("em",{parentName:"p"},"< HTTP/1.1 200 OK")),(0,r.kt)("p",null,"Followed by several lines summarizing the completed session."),(0,r.kt)("p",null,"Wait a couple minutes, then verify that the data has made it into cassandra:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <CASSANDRA PASSWORD>\nselect * from tararam.dt_metric_value;\n")),(0,r.kt)("p",null,"You should see several hundreds of lines of our data in the cassandra tables...\npage through or hit ",(0,r.kt)("strong",{parentName:"p"},"Ctrl-C")," when you're satisfied that data is making it into\ncassandra:"),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(19262).Z,width:"1160",height:"359"})),(0,r.kt)("p",null,"The next step is to run the Metric Manager extractor to ingest the data from\nCassandra for analysis and machine learning. Run the following command to start\nour BIGBLUE topic, then run extraction. Starting the topic may take a few\nminutes:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"/opt/IBM/scanalytics/analytics/bin/start.sh -t=BIGBLUE\n/opt/IBM/scanalytics/analytics/bin/admin.sh run_extractor_instance -t=BIGBLUE -s=20220723-0000 -e=20220806-1200\n")),(0,r.kt)("p",null,"If you want to monitor the progress of data ingestion for a topic, a log file\n/opt/IBM/scanalytics/analytics/log/\\<TOPICNAME",">","/AnalyticsBIGBLUE_log_AnalyticsOperator.log.\nYou can watch the progression of the ingestion and monitor for error messages by\nusing the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"tail -f /opt/IBM/scanalytics/analytics/log/BIGBLUE/AnalyticsBIGBLUE_log_AnalyticsOperator.log\n")),(0,r.kt)("p",null,"The log file will show where it is in terms of what time interval it is\ncollecting and analyzing, the amount of KPIs and how many KPIs are being\nevaluated for each algorithm (e.g. robust bounds, granger, flat line, etc). If\nyou have any issues with ingestion, this log file can help you identify errors\nthat may be attributing to the problem."),(0,r.kt)("p",null,"Take a break for a few minutes. The ingestion will complete in about 10 minutes.\nWhen mediation is complete, follow the same procedure as in the previous lab to\nverify that the data was ingested and showing up. Open Firefox and log in as\n'ncoadmin' / '",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("span",{style:{color:"green"}},"<LAB PASSWORD",">")),'\', then\nclick on the snowflake icon on the left menu pane and selecting "Service\nDiangosis Anomaly Search", and drilling into one of the anomalies:'),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(59492).Z,width:"932",height:"394"})),(0,r.kt)("p",null,"For live ongoing data ingestion using the REST interface, you would start the\nMetric Manager topic, then start the extractor ","*","without a start time or end\ntime","*",". That puts the Metric Manager extractor in live mode, and for each time\ninterval (e.g. every 5 minutes), the extractor will pull the metrics that were\nposted to the REST interface for the last interval, and process them live."),(0,r.kt)("p",null,"You can create custom scripts to post metrics to the REST service. Additionally,\nour off-the-shelf Mediation Packs can collect metric from various sources (e.g.\nSplunk, Dynatrace, etc) and output to either CSV files for PI to collect, or can\npost to the REST Mediation Service. These off-the-shelf Mediation Packs\ncurrently work with Metric Manager on VM, but will in the future also work with\nWatson AIOps Metric Anomaly Detection."),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(12938).Z,width:"1508",height:"772"})),(0,r.kt)("p",null,"Note also that the REST Mediation Service code is the same code that is used in\nthe Metric Anomaly Detection component of Watson AIOps, which you will be\nworking with in the final lab."),(0,r.kt)("p",null,"That concludes this lab. You learned how to install and configure the REST\nMediation Service, how to start the components that make up the service, and\nalso how to POST data to the service."))}d.isMDXComponent=!0},59492:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Picture1-5b8c42eeb5d2994be0e6b5c9407c9bdb.png"},19262:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/lab6-add1-1e560eae6eeec4b25258886ca048a404.png"},12938:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/lab6-add2-502f08f1c431fc689803c913e6034bde.png"}}]);