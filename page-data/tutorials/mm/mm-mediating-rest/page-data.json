{"componentChunkName":"component---src-pages-tutorials-mm-mm-mediating-rest-index-mdx","path":"/tutorials/mm/mm-mediating-rest/","result":{"pageContext":{"frontmatter":{"title":"REST Data Mediation","description":"This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager"},"relativePagePath":"/tutorials/mm/mm-mediating-rest/index.mdx","titleType":"page","MdxNode":{"id":"1f6b1ad2-cb61-5a68-a3d7-d990daeec1fa","children":[],"parent":"24b7a9ca-2adc-5d92-a5a7-a181254626ad","internal":{"content":"---\r\ntitle: REST Data Mediation\r\ndescription: This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager\r\n---\r\n\r\n<AnchorLinks>\r\n  <AnchorLink>6-1: Lab Introduction</AnchorLink>\r\n  <AnchorLink>6-2: Starting Cassandra</AnchorLink>\r\n  <AnchorLink>6-3: Create a topic for REST data</AnchorLink>\r\n  <AnchorLink>6-4: Configuring the REST mediation service</AnchorLink>\r\n  <AnchorLink>6-5: Starting Kafka</AnchorLink>\r\n  <AnchorLink>6-6: Starting Spark</AnchorLink>\r\n  <AnchorLink>6-7: Starting the REST Mediation Service</AnchorLink>\r\n  <AnchorLink>6-8: Send data to the REST Mediation Service</AnchorLink>\r\n</AnchorLinks>\r\n\r\n## 6-1: Lab Introduction\r\n\r\n In lab 3 we created a model for metric data that resided in CSV files. Metric Manager can also ingest data via a REST interface. The REST interface can accept pre-defined JSON payloads and process them for analysis and machine learning.\r\n\r\n Since the definition of the JSON payload describes the model within its structure, it is not required to use the Mediation Tool to create a model. The pre-defined JSON format defines the model, and it is only necessary to ensure that the JSON payload adheres to the required format. This format is also the same as the new version of Watson AIOps container-based Metric Anomaly Detection component that is being actively developed, which we will be working with in the final lab.\r\n\r\n This lab will go through the various components that make up the REST mediation service. We will configure the components that we installed in lab 1, start the mediation service, and use a simple script to send data to the REST mediation service, and view the results.\r\n\r\n\r\n## 6-2: Starting Cassandra\r\n\r\n Data that is sent to the REST mediation service is stored in a Cassandra database. The \"run\\_extractor\\_instance\" command will pull metrics from Cassandra for analysis. For production deployments, and depending on metric load, it is possible to use a distributed installation of Cassandra for high availability and performance. For this lab we will be configuring a single Cassandra instance.\r\n\r\n### Configuring startup:<br/>\r\n***\r\n\r\n As the 'scadmin' user, start Cassandra with the following command:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n```\r\n\r\n Run the following command to verify that Cassandra is running:\r\n\r\n```sh\r\nps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\r\n```\r\n\r\n Next, using your preferred text editing tool, edit the /opt/IBM/apache-cassandra-3.11.10/bin/stop-server script and add the following line to the end of the file:\r\n\r\n`pgrep -u $(whoami) -f cassandra | xargs -t -i kill {}`\r\n\r\n Run the 'stop-server' command to stop the Cassandra server:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\r\n```\r\n\r\nAnd ensure the stop script stopped Cassandra:\r\n\r\n```sh\r\nps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\r\n```\r\n\r\n Clean up the Cassandra data folder:\r\n\r\n```sh\r\ncd /opt/IBM/apache-cassandra-3.11.10/data/data/\r\nrm -rf system\r\n```\r\n\r\n Start Cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n```\r\n\r\nList the Cassandra servers:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\r\n```\r\n\r\nYou should see a response similar to the following, indicating that it is listening 127.0.0.1:\r\n\r\n`UN 127.0.0.1 133.29 KiB 256 100.0% b2f89d8c-dd23-451c-907a-59b72dc4d18c rack1`\r\n\r\n### Configure Cassandra with a username and password\r\n\r\n For security, it is required to configure Cassandra with a username and password so the topic extractor can securely authenticate with Cassandra and extract metric data. Using your preferred text editor, edit the /opt/IBM/apache-cassandra-3.11.10/conf/cassandra.yaml and change the **authenticator** line to:\r\n\r\n`authenticator: PasswordAuthenticator`\r\n\r\n Save the file and restart Cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\r\n```\r\n\r\n Finally, verify password authentication is working by running cqlsh, passing in username and **<span style=\"color:green\"><CASSANDRA DEFAULT PASSWORD\\></span>** as the password.\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <DEFAULT CASSANDRA PASSWORD>\r\n```\r\n\r\nYou should see a successful connect, and arrive at the cqlsh prompt. \r\n\r\n`cassandra@cqlsh>`\r\n\r\n Use the following commands to change the default 'cassandra' user's password to either the **<span style=\"color:green\"><CASSANDRA PASSWORD\\></span>** provided by the lab proctor, or the cassandra password you chose if you were required to use an alternative:\r\n\r\n```sh\r\ncassandra@cqlsh> alter user cassandra with password '<CASSANDRA PASSWORD>';\r\ncassandra@cqlsh> quit\r\n```\r\n\r\n Encrypt and copy the default Cassandra password using the following commands. When prompted, enter <CASSANDRA PASSWORD\\> as the password:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh passwd -c $PI_HOME/config/cassandra.properties connection.password\r\n```\r\n\r\n Inspect the encrypted password in the following file using the following command:\r\n\r\n```sh\r\ncat $PI_HOME/config/cassandra.properties\r\n```\r\n\r\n# **!!! DANGER WILL ROBINSON !!! ** \r\n** !! NOTE !!: If the encrypted Cassandra password you inspected in the previous command begins with the \"+\" character, you will need to select an alternative password for the Cassandra 'cassandra' user. This is due to a current defect in the REST mediation code. Try making up an alternative password of your choice, encrypt it, and if it doesn't begin with a \"+\" character, use your chosen password an alternative. Then, in the next section, use your alternative password in place of <CASSANDRA PASSWORD\\> **\r\n\r\n\r\n\r\n## 6-3: Create a topic for REST data\r\n\r\n You can store metric data data derived from REST only in the topic that you use to extract the REST Mediation Service data. You cannot use an existing topic if it contains data from a CSV file or database. However, you can use an existing topic if it does not contain any data or if it contains only JSON data. We will reconfigure our BIGBLUE topic to accept REST data.\r\n\r\n Return to a terminal window and clear the topic using the following commands. When prompted, type \" **I am sure\"** and press enter. When it asks whether you want to clear out the database, type \" **Yes**\" and press enter. This will clean out all of the data from the topic and reset it to pristine.\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/stop.sh -s\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh cleanup -t=BIGBLUE\r\n```\r\n\r\n### Modify the topic to extract data from Cassandra:\r\n\r\n The following command configures the topic to connect to cassandra on localhost:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.host localhost\r\n```\r\n\r\n Obtain the encrypted cassandra password, copying the text that follows **cassandra.password=**\r\n\r\n```sh\r\ncat $PI_HOME/config/cassandra.properties\r\n```\r\n\r\nSet the encrypted value for our BIGBLUE topic, pasting the value for 'connection.password' obtained from the previous output:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.password <ENCRYPTED CASSANDRA PASSWORD>\r\n```\r\n\r\n Set the Cassandra user for the topic to 'cassandra':\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.username cassandra\r\n```\r\n\r\n## 6-4: Configuring the REST mediation service\r\n\r\n The next step in configuring the REST integration requires configuring the REST mediation service mediation configuration files. We will encrypt the Cassandra password and store it in the Mediation Service yaml files. We will use the user 'piadmin' to encrypt the password, then update the appropriate mediation service yaml files. The reason we need to use a separate user is because we require Java 11 for the IBM REST mediation code itself, while the rest of the REST mediation components (Cassandra, spark, kafka) requires Java 8.\r\n\r\n Sudo to the 'piadmin' user, using the password **<span style=\"color:green\"><LAB PASSWORD\\></span>** and run the password encryption utility, passing **<span style=\"color:green\"><CASSANDRA PASSWORD\\></span>** as the argument to the encrypt_password.sh command:\r\n\r\n```sh\r\nsudo su - piadmin\r\ncd /opt/IBM/pi-mediation-1.0.4\r\n./encrypt_password.sh <CASSANDRA PASSWORD> \r\n```\r\n\r\nThe \"encrypt\\_password.sh\" tool will print the encrypted password. Copy the encrypted password.\r\n\r\n Using your preferred text editor, edit the /opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and modify the \"cassandra.encrypted.password:\" entry, paste the encrypted password text.\r\n\r\n`cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`\r\n\r\n Save the file and exit. \r\n\r\n Next, edit the /opt/IBM/pi-mediation-1.0.4/config/metric-spark.yml file and modify the following entries in the file:\r\n\r\n`spark.cassandra.auth.username: cassandra`  \r\n`spark.cassandra.auth.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`  \r\n`cassandra.username: cassandra`  \r\n`cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`  \r\n\r\n Save the file and exit.\r\n\r\n### Configuring authentication for the REST mediation service\r\n\r\n The REST API requires that you set a password to ensure that connections are authenticated. We will use the password **<span style=\"color:green\"><LAB PASSWORD\\></span>** as our API password. As the piadmin user, encrypt the password, making sure to substitute **<span style=\"color:green\"><LAB PASSWORD\\></span>** with the lab password provided earlier:\r\n\r\n```sh\r\ncd /opt/IBM/pi-mediation-1.0.4/\r\n./encrypt_password.sh <LAB PASSWORD>\r\n```\r\n\r\n Copy the encrypted password.\r\n\r\n Once you have obtained and copied the encrypted password for the REST service, edit the \"/opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and modify the entry 'metrics.api.encrypted.password' entry, pasting the encrypted password.\r\n\r\n`metrics.api.encrypted.password: <ENCRYPTED LAB PASSWORD>`\r\n\r\n\r\n## 6-5: Starting Kafka\r\n\r\n Copy the startup script for Kafka to the kafka directory, then run the script to start kafka:\r\n\r\n```sh\r\ncp /home/piadmin/start-pi-kafka.sh /opt/IBM/kafka_2.13-2.6.2/\r\n/opt/IBM/kafka_2.13-2.6.2/start-pi-kafka.sh\r\n```\r\n\r\n Wait about 30 seconds, then verify that it is running:\r\n\r\n```sh\r\nps -ef |grep kafka.Kafka |grep -v grep\r\n```\r\n\r\n\r\n## 6-6: Starting Spark\r\n\r\n\r\n Spark must be run as the 'piadmin' user. Start the Spark services by running the following command: \r\n\r\n```sh\r\n/opt/IBM/spark-3.1.2-bin-hadoop3.2/sbin/start-all.sh\r\n```\r\n\r\n Use **<span style=\"color:green\"><LAB PASSWORD\\></span>** for the password if it prompts.\r\n\r\n\r\n## 6-7: Starting the REST mediation service\r\n\r\n Become the piadmin user (if you're not already) and start the service. The service must be started from within the mediation directory:\r\n\r\n```sh\r\ncd /opt/IBM/pi-mediation-1.0.4/\r\n./run_service.sh\r\n```\r\n\r\n Next, verify that the mediation service is running:\r\n\r\n```sh\r\nps -ef |grep yml\r\n```\r\n\r\nYou should see the following two java processes running:\r\n\r\n`java -Xms1G -Xmx2G -jar libs/ea-metric-spark.jar server config/metric-spark.yml`<br/>\r\n`java -Xms1G -Xmx2G -jar libs/ea-metric-api.jar server config/metric-api-service.yml`\r\n\r\n\r\n## 6-8: Send data to the REST interface:\r\n\r\n If you are still the 'piadmin' user, exit back to the 'scadmin' user, or open a new terminal window. We will be using secure copy to obtain a JSON file that contains metrics that we will be sending to the REST service. Run the following commands as the scadmin user to obtain the file. :\r\n\r\n```sh\r\ncd /home/scadmin/BookInfoDemo/data/bookinfo\r\nwget http://150.238.93.118/BookInfoJson-20220721-0000__20220806-1200.json \r\n```\r\n\r\n When the file transfer completes, you can use curl to send the data to the REST service. Execute the following commands to send JSON data to the Metric Manager REST mediation service, making sure to substiture **<span style=\"color:green\"><LAB PASSWORD\\></span>**:\r\n\r\n```sh\r\ncurl -vX POST --user \"system:<LAB PASSWORD>\" --header \"Content-Type: application/json\" --header \"X-TenantID: BIGBLUE\" http://pi-template.Hybrid-Squad.cloud:18080/metrics/api/1.0/metrics -d @BookInfoJson-20220721-0000__20220806-1200.json\r\n```\r\n\r\nThe key response lines that you will see when the load is successful are:\r\n\r\n\r\n_< HTTP/1.1 100 Continue_<br/>\r\n_< HTTP/1.1 200 OK_\r\n\r\nFollowed by several lines summarizing the completed session.\r\n\r\n Wait a couple minutes, then verify that the data has made it into cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <CASSANDRA PASSWORD>\r\nselect * from tararam.dt_metric_value;\r\n```\r\n\r\nYou should see several hundreds of lines of our data in the cassandra tables... page through or hit **Ctrl-C** when you're satisfied that data is making it into cassandra:\r\n\r\n ![](images/lab6-add1.png)\r\n\r\n\r\n\r\n The next step is to run the Metric Manager extractor to ingest the data from Cassandra for analysis and machine learning. Run the following command to start our BIGBLUE topic, then run extraction. Starting the topic may take a few minutes:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/start.sh -t=BIGBLUE\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh run_extractor_instance -t=BIGBLUE -s=20220723-0000 -e=20220806-1200\r\n```\r\n\r\n If you want to monitor the progress of data ingestion for a topic, a log file /opt/IBM/scanalytics/analytics/log/\\<TOPICNAME\\>/AnalyticsBIGBLUE\\_log\\_AnalyticsOperator.log. You can watch the progression of the ingestion and monitor for error messages by using the following command:\r\n\r\n```sh\r\ntail -f /opt/IBM/scanalytics/analytics/log/BIGBLUE/AnalyticsBIGBLUE_log_AnalyticsOperator.log\r\n```\r\n\r\n The log file will show where it is in terms of what time interval it is collecting and analyzing, the amount of KPIs and how many KPIs are being evaluated for each algorithm (e.g. robust bounds, granger, flat line, etc). If you have any issues with ingestion, this log file can help you identify errors that may be attributing to the problem.\r\n\r\n Take a break for a few minutes. The ingestion will complete in about 10 minutes. When mediation is complete, follow the same procedure as in the previous lab to verify that the data was ingested and showing up. Open Firefox and log in as 'ncoadmin' / '**<span style=\"color:green\"><LAB PASSWORD\\></span>**', then click on the snowflake icon on the left menu pane and selecting \"Service Diangosis Anomaly Search\", and drilling into one of the anomalies:\r\n\r\n ![](images/Picture1.png)\r\n\r\n For live ongoing data ingestion using the REST interface, you would start the Metric Manager topic, then start the extractor \\*without a start time or end time\\*. That puts the Metric Manager extractor in live mode, and for each time interval (e.g. every 5 minutes), the extractor will pull the metrics that were posted to the REST interface for the last interval, and process them live. \r\n\r\n You can create custom scripts to post metrics to the REST service. Additionally, our off-the-shelf Mediation Packs can collect metric from various sources (e.g. Splunk, Dynatrace, etc) and output to either CSV files for PI to collect, or can post to the REST Mediation Service. These off-the-shelf Mediation Packs currently work with Metric Manager on VM, but will in the future also work with Watson AIOps Metric Anomaly Detection.\r\n\r\n ![](images/lab6-add2.png)\r\n\r\n Note also that the REST Mediation Service code is the same code that is used in the Metric Anomaly Detection component of Watson AIOps, which you will be working with in the final lab.\r\n\r\n\r\n That concludes this lab. You learned how to install and configure the REST Mediation Service, how to start the components that make up the service, and also how to POST data to the service.\r\n\r\n","type":"Mdx","contentDigest":"5e85a8e547b05fb1623502e8b23220b1","owner":"gatsby-plugin-mdx","counter":956},"frontmatter":{"title":"REST Data Mediation","description":"This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager"},"exports":{},"rawBody":"---\r\ntitle: REST Data Mediation\r\ndescription: This lab will teach you how to ingest metric data from the REST mediation service of Metric Manager\r\n---\r\n\r\n<AnchorLinks>\r\n  <AnchorLink>6-1: Lab Introduction</AnchorLink>\r\n  <AnchorLink>6-2: Starting Cassandra</AnchorLink>\r\n  <AnchorLink>6-3: Create a topic for REST data</AnchorLink>\r\n  <AnchorLink>6-4: Configuring the REST mediation service</AnchorLink>\r\n  <AnchorLink>6-5: Starting Kafka</AnchorLink>\r\n  <AnchorLink>6-6: Starting Spark</AnchorLink>\r\n  <AnchorLink>6-7: Starting the REST Mediation Service</AnchorLink>\r\n  <AnchorLink>6-8: Send data to the REST Mediation Service</AnchorLink>\r\n</AnchorLinks>\r\n\r\n## 6-1: Lab Introduction\r\n\r\n In lab 3 we created a model for metric data that resided in CSV files. Metric Manager can also ingest data via a REST interface. The REST interface can accept pre-defined JSON payloads and process them for analysis and machine learning.\r\n\r\n Since the definition of the JSON payload describes the model within its structure, it is not required to use the Mediation Tool to create a model. The pre-defined JSON format defines the model, and it is only necessary to ensure that the JSON payload adheres to the required format. This format is also the same as the new version of Watson AIOps container-based Metric Anomaly Detection component that is being actively developed, which we will be working with in the final lab.\r\n\r\n This lab will go through the various components that make up the REST mediation service. We will configure the components that we installed in lab 1, start the mediation service, and use a simple script to send data to the REST mediation service, and view the results.\r\n\r\n\r\n## 6-2: Starting Cassandra\r\n\r\n Data that is sent to the REST mediation service is stored in a Cassandra database. The \"run\\_extractor\\_instance\" command will pull metrics from Cassandra for analysis. For production deployments, and depending on metric load, it is possible to use a distributed installation of Cassandra for high availability and performance. For this lab we will be configuring a single Cassandra instance.\r\n\r\n### Configuring startup:<br/>\r\n***\r\n\r\n As the 'scadmin' user, start Cassandra with the following command:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n```\r\n\r\n Run the following command to verify that Cassandra is running:\r\n\r\n```sh\r\nps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\r\n```\r\n\r\n Next, using your preferred text editing tool, edit the /opt/IBM/apache-cassandra-3.11.10/bin/stop-server script and add the following line to the end of the file:\r\n\r\n`pgrep -u $(whoami) -f cassandra | xargs -t -i kill {}`\r\n\r\n Run the 'stop-server' command to stop the Cassandra server:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\r\n```\r\n\r\nAnd ensure the stop script stopped Cassandra:\r\n\r\n```sh\r\nps -ef |grep org.apache.cassandra.service.CassandraDaemon |grep -v grep\r\n```\r\n\r\n Clean up the Cassandra data folder:\r\n\r\n```sh\r\ncd /opt/IBM/apache-cassandra-3.11.10/data/data/\r\nrm -rf system\r\n```\r\n\r\n Start Cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n```\r\n\r\nList the Cassandra servers:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\r\n```\r\n\r\nYou should see a response similar to the following, indicating that it is listening 127.0.0.1:\r\n\r\n`UN 127.0.0.1 133.29 KiB 256 100.0% b2f89d8c-dd23-451c-907a-59b72dc4d18c rack1`\r\n\r\n### Configure Cassandra with a username and password\r\n\r\n For security, it is required to configure Cassandra with a username and password so the topic extractor can securely authenticate with Cassandra and extract metric data. Using your preferred text editor, edit the /opt/IBM/apache-cassandra-3.11.10/conf/cassandra.yaml and change the **authenticator** line to:\r\n\r\n`authenticator: PasswordAuthenticator`\r\n\r\n Save the file and restart Cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/stop-server\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cassandra > /opt/IBM/apache-cassandra-3.11.10/cassandra.out 2>&1\r\n/opt/IBM/apache-cassandra-3.11.10/bin/nodetool status\r\n```\r\n\r\n Finally, verify password authentication is working by running cqlsh, passing in username and **<span style=\"color:green\"><CASSANDRA DEFAULT PASSWORD\\></span>** as the password.\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <DEFAULT CASSANDRA PASSWORD>\r\n```\r\n\r\nYou should see a successful connect, and arrive at the cqlsh prompt. \r\n\r\n`cassandra@cqlsh>`\r\n\r\n Use the following commands to change the default 'cassandra' user's password to either the **<span style=\"color:green\"><CASSANDRA PASSWORD\\></span>** provided by the lab proctor, or the cassandra password you chose if you were required to use an alternative:\r\n\r\n```sh\r\ncassandra@cqlsh> alter user cassandra with password '<CASSANDRA PASSWORD>';\r\ncassandra@cqlsh> quit\r\n```\r\n\r\n Encrypt and copy the default Cassandra password using the following commands. When prompted, enter <CASSANDRA PASSWORD\\> as the password:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh passwd -c $PI_HOME/config/cassandra.properties connection.password\r\n```\r\n\r\n Inspect the encrypted password in the following file using the following command:\r\n\r\n```sh\r\ncat $PI_HOME/config/cassandra.properties\r\n```\r\n\r\n# **!!! DANGER WILL ROBINSON !!! ** \r\n** !! NOTE !!: If the encrypted Cassandra password you inspected in the previous command begins with the \"+\" character, you will need to select an alternative password for the Cassandra 'cassandra' user. This is due to a current defect in the REST mediation code. Try making up an alternative password of your choice, encrypt it, and if it doesn't begin with a \"+\" character, use your chosen password an alternative. Then, in the next section, use your alternative password in place of <CASSANDRA PASSWORD\\> **\r\n\r\n\r\n\r\n## 6-3: Create a topic for REST data\r\n\r\n You can store metric data data derived from REST only in the topic that you use to extract the REST Mediation Service data. You cannot use an existing topic if it contains data from a CSV file or database. However, you can use an existing topic if it does not contain any data or if it contains only JSON data. We will reconfigure our BIGBLUE topic to accept REST data.\r\n\r\n Return to a terminal window and clear the topic using the following commands. When prompted, type \" **I am sure\"** and press enter. When it asks whether you want to clear out the database, type \" **Yes**\" and press enter. This will clean out all of the data from the topic and reset it to pristine.\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/stop.sh -s\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh cleanup -t=BIGBLUE\r\n```\r\n\r\n### Modify the topic to extract data from Cassandra:\r\n\r\n The following command configures the topic to connect to cassandra on localhost:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.host localhost\r\n```\r\n\r\n Obtain the encrypted cassandra password, copying the text that follows **cassandra.password=**\r\n\r\n```sh\r\ncat $PI_HOME/config/cassandra.properties\r\n```\r\n\r\nSet the encrypted value for our BIGBLUE topic, pasting the value for 'connection.password' obtained from the previous output:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.password <ENCRYPTED CASSANDRA PASSWORD>\r\n```\r\n\r\n Set the Cassandra user for the topic to 'cassandra':\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh set -t=BIGBLUE cassandra.username cassandra\r\n```\r\n\r\n## 6-4: Configuring the REST mediation service\r\n\r\n The next step in configuring the REST integration requires configuring the REST mediation service mediation configuration files. We will encrypt the Cassandra password and store it in the Mediation Service yaml files. We will use the user 'piadmin' to encrypt the password, then update the appropriate mediation service yaml files. The reason we need to use a separate user is because we require Java 11 for the IBM REST mediation code itself, while the rest of the REST mediation components (Cassandra, spark, kafka) requires Java 8.\r\n\r\n Sudo to the 'piadmin' user, using the password **<span style=\"color:green\"><LAB PASSWORD\\></span>** and run the password encryption utility, passing **<span style=\"color:green\"><CASSANDRA PASSWORD\\></span>** as the argument to the encrypt_password.sh command:\r\n\r\n```sh\r\nsudo su - piadmin\r\ncd /opt/IBM/pi-mediation-1.0.4\r\n./encrypt_password.sh <CASSANDRA PASSWORD> \r\n```\r\n\r\nThe \"encrypt\\_password.sh\" tool will print the encrypted password. Copy the encrypted password.\r\n\r\n Using your preferred text editor, edit the /opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and modify the \"cassandra.encrypted.password:\" entry, paste the encrypted password text.\r\n\r\n`cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`\r\n\r\n Save the file and exit. \r\n\r\n Next, edit the /opt/IBM/pi-mediation-1.0.4/config/metric-spark.yml file and modify the following entries in the file:\r\n\r\n`spark.cassandra.auth.username: cassandra`  \r\n`spark.cassandra.auth.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`  \r\n`cassandra.username: cassandra`  \r\n`cassandra.encrypted.password: <ENCRYPTED CASSANDRA PASSWORD>`  \r\n\r\n Save the file and exit.\r\n\r\n### Configuring authentication for the REST mediation service\r\n\r\n The REST API requires that you set a password to ensure that connections are authenticated. We will use the password **<span style=\"color:green\"><LAB PASSWORD\\></span>** as our API password. As the piadmin user, encrypt the password, making sure to substitute **<span style=\"color:green\"><LAB PASSWORD\\></span>** with the lab password provided earlier:\r\n\r\n```sh\r\ncd /opt/IBM/pi-mediation-1.0.4/\r\n./encrypt_password.sh <LAB PASSWORD>\r\n```\r\n\r\n Copy the encrypted password.\r\n\r\n Once you have obtained and copied the encrypted password for the REST service, edit the \"/opt/IBM/pi-mediation-1.0.4/config/metric-api-service.yml file and modify the entry 'metrics.api.encrypted.password' entry, pasting the encrypted password.\r\n\r\n`metrics.api.encrypted.password: <ENCRYPTED LAB PASSWORD>`\r\n\r\n\r\n## 6-5: Starting Kafka\r\n\r\n Copy the startup script for Kafka to the kafka directory, then run the script to start kafka:\r\n\r\n```sh\r\ncp /home/piadmin/start-pi-kafka.sh /opt/IBM/kafka_2.13-2.6.2/\r\n/opt/IBM/kafka_2.13-2.6.2/start-pi-kafka.sh\r\n```\r\n\r\n Wait about 30 seconds, then verify that it is running:\r\n\r\n```sh\r\nps -ef |grep kafka.Kafka |grep -v grep\r\n```\r\n\r\n\r\n## 6-6: Starting Spark\r\n\r\n\r\n Spark must be run as the 'piadmin' user. Start the Spark services by running the following command: \r\n\r\n```sh\r\n/opt/IBM/spark-3.1.2-bin-hadoop3.2/sbin/start-all.sh\r\n```\r\n\r\n Use **<span style=\"color:green\"><LAB PASSWORD\\></span>** for the password if it prompts.\r\n\r\n\r\n## 6-7: Starting the REST mediation service\r\n\r\n Become the piadmin user (if you're not already) and start the service. The service must be started from within the mediation directory:\r\n\r\n```sh\r\ncd /opt/IBM/pi-mediation-1.0.4/\r\n./run_service.sh\r\n```\r\n\r\n Next, verify that the mediation service is running:\r\n\r\n```sh\r\nps -ef |grep yml\r\n```\r\n\r\nYou should see the following two java processes running:\r\n\r\n`java -Xms1G -Xmx2G -jar libs/ea-metric-spark.jar server config/metric-spark.yml`<br/>\r\n`java -Xms1G -Xmx2G -jar libs/ea-metric-api.jar server config/metric-api-service.yml`\r\n\r\n\r\n## 6-8: Send data to the REST interface:\r\n\r\n If you are still the 'piadmin' user, exit back to the 'scadmin' user, or open a new terminal window. We will be using secure copy to obtain a JSON file that contains metrics that we will be sending to the REST service. Run the following commands as the scadmin user to obtain the file. :\r\n\r\n```sh\r\ncd /home/scadmin/BookInfoDemo/data/bookinfo\r\nwget http://150.238.93.118/BookInfoJson-20220721-0000__20220806-1200.json \r\n```\r\n\r\n When the file transfer completes, you can use curl to send the data to the REST service. Execute the following commands to send JSON data to the Metric Manager REST mediation service, making sure to substiture **<span style=\"color:green\"><LAB PASSWORD\\></span>**:\r\n\r\n```sh\r\ncurl -vX POST --user \"system:<LAB PASSWORD>\" --header \"Content-Type: application/json\" --header \"X-TenantID: BIGBLUE\" http://pi-template.Hybrid-Squad.cloud:18080/metrics/api/1.0/metrics -d @BookInfoJson-20220721-0000__20220806-1200.json\r\n```\r\n\r\nThe key response lines that you will see when the load is successful are:\r\n\r\n\r\n_< HTTP/1.1 100 Continue_<br/>\r\n_< HTTP/1.1 200 OK_\r\n\r\nFollowed by several lines summarizing the completed session.\r\n\r\n Wait a couple minutes, then verify that the data has made it into cassandra:\r\n\r\n```sh\r\n/opt/IBM/apache-cassandra-3.11.10/bin/cqlsh -u cassandra -p <CASSANDRA PASSWORD>\r\nselect * from tararam.dt_metric_value;\r\n```\r\n\r\nYou should see several hundreds of lines of our data in the cassandra tables... page through or hit **Ctrl-C** when you're satisfied that data is making it into cassandra:\r\n\r\n ![](images/lab6-add1.png)\r\n\r\n\r\n\r\n The next step is to run the Metric Manager extractor to ingest the data from Cassandra for analysis and machine learning. Run the following command to start our BIGBLUE topic, then run extraction. Starting the topic may take a few minutes:\r\n\r\n```sh\r\n/opt/IBM/scanalytics/analytics/bin/start.sh -t=BIGBLUE\r\n/opt/IBM/scanalytics/analytics/bin/admin.sh run_extractor_instance -t=BIGBLUE -s=20220723-0000 -e=20220806-1200\r\n```\r\n\r\n If you want to monitor the progress of data ingestion for a topic, a log file /opt/IBM/scanalytics/analytics/log/\\<TOPICNAME\\>/AnalyticsBIGBLUE\\_log\\_AnalyticsOperator.log. You can watch the progression of the ingestion and monitor for error messages by using the following command:\r\n\r\n```sh\r\ntail -f /opt/IBM/scanalytics/analytics/log/BIGBLUE/AnalyticsBIGBLUE_log_AnalyticsOperator.log\r\n```\r\n\r\n The log file will show where it is in terms of what time interval it is collecting and analyzing, the amount of KPIs and how many KPIs are being evaluated for each algorithm (e.g. robust bounds, granger, flat line, etc). If you have any issues with ingestion, this log file can help you identify errors that may be attributing to the problem.\r\n\r\n Take a break for a few minutes. The ingestion will complete in about 10 minutes. When mediation is complete, follow the same procedure as in the previous lab to verify that the data was ingested and showing up. Open Firefox and log in as 'ncoadmin' / '**<span style=\"color:green\"><LAB PASSWORD\\></span>**', then click on the snowflake icon on the left menu pane and selecting \"Service Diangosis Anomaly Search\", and drilling into one of the anomalies:\r\n\r\n ![](images/Picture1.png)\r\n\r\n For live ongoing data ingestion using the REST interface, you would start the Metric Manager topic, then start the extractor \\*without a start time or end time\\*. That puts the Metric Manager extractor in live mode, and for each time interval (e.g. every 5 minutes), the extractor will pull the metrics that were posted to the REST interface for the last interval, and process them live. \r\n\r\n You can create custom scripts to post metrics to the REST service. Additionally, our off-the-shelf Mediation Packs can collect metric from various sources (e.g. Splunk, Dynatrace, etc) and output to either CSV files for PI to collect, or can post to the REST Mediation Service. These off-the-shelf Mediation Packs currently work with Metric Manager on VM, but will in the future also work with Watson AIOps Metric Anomaly Detection.\r\n\r\n ![](images/lab6-add2.png)\r\n\r\n Note also that the REST Mediation Service code is the same code that is used in the Metric Anomaly Detection component of Watson AIOps, which you will be working with in the final lab.\r\n\r\n\r\n That concludes this lab. You learned how to install and configure the REST Mediation Service, how to start the components that make up the service, and also how to POST data to the service.\r\n\r\n","fileAbsolutePath":"C:/Users/103537778/git/waiops-tech-jam/src/pages/tutorials/mm/mm-mediating-rest/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}